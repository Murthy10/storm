%!TEX root = ../dissertation.tex
\begin{savequote}[75mm]
A good idea is about ten percent and implementation and hard work, and luck is 90 percent.
\qauthor{Guy Kawasaki}
\end{savequote}

\chapter{Implementation}
The final chapter is about the implementation with Apache Storm to solve the defined queries and to do the benchmarks.
The idea of the test scenario is to use "Augmented Diffs" from OpenStreetMap as a stream.
The diffs extend the ordinary minutely diffs of OpenStreetMap with more information.
The result contains all the nodes, ways and relations changed durring the time periode.

\newpage

\section{Test Setup}
For the implementation there is a given test setup.
The OpenStreetMap augmented diffs are minutelly collected by a script executed as a cron job.
The script acts as an producer for Apache Kafka and the data is now accessible from these message queue.
Furthermore the data is ready to be consumed by the stream processing engine and in the current case ready for Apache Storm.

\begin{figure}[H]
\centering
\captionsetup{justification=centering}
\includegraphics[width=0.6\textwidth]{images/test_setup.png}
\caption[Test setup]{Test setup}
\end{figure}


\section{Queries}
The following list is about the queries which has to be done on the Augmented Diff stream.

\begin{itemize}
\item[A)] Leader board of top 10 OSM active users
\item[B)] Leader board of top 10 OSM objects added
\item[C)] Node objects with suspicious keys and values
\item[D)] Way objects with only user tag "area=yes" without other user tags
\end{itemize}

\newpage
\section{Topology of the queries}
With the queries we have to solve in mind, I have to design a fitting arcitecture for Apache Storm.
So the first step is to get the messages from Kafka, then converte the message string to JSON,
do the queries on the JSON stream and finally make the result available.\\
\medskip
This leads me to the following Apache Storm topology:
\begin{figure}[H]
\centering
\captionsetup{justification=centering}
\includegraphics[width=1.0\textwidth]{images/impl_topic.png}
\caption[Topic for queries]{Topic for queries}
\end{figure}
Let's have a closer look to some implementation details of the image above.
To read the messages from the Kafka osm topic, a topic is something lika a tabel in a relational database, I used the \textit{KafkaSpout} class from org.apache.storm.kafka.
This class handles the communication with Kafka and acts like a consumer, furthermore it makes the string messages availible for the bolts.

The consumed messages are in text format and needs to be casted to JSON for this purpose I implemented a \textit{StringtoJsonBolt} class.

After this conversion I used an all grouping topology approach, which emits the JSON data to all connected bolts.

Every following bolt is responsible for the defined querie, thus leads to the classes \textit{UserCountBolt}, \textit{ObjectCountbolt}, \textit{SuspicousBolt} and \textit{AreaYesBolt}.
When the bolts have done their queries on the JSON data there is always a connected \textit{KafkaBolt} class from org.apache.storm.kafka,
which finally publishs the results to the fitting Kafka topic.

And makes the data available for presentation tasks or further processing.

\newpage
\section{Benchmark}

Benchmarking is a very difficult topic and strongly depends on various parameters like the underlying hardware.
Thus we decide to make this as hardware independent as possible.
The idea is to produce a lot of small message, like IoT does,
and count all of them. Then repeat this process and relate the number of processed messages with the time spent.

For the message generation we had a small python script called "benchmark.py" which produces as much messages as you want
and provide them with Apache Kafka.
The messages have got the following structure:

\begin{table}[h!]
 \centering
 \begin{tabular}{llllll}
   \textbf{packetId}  & \textbf{TopicName} & \textbf{qos} & \textbf{retainFlag} & \textbf{payload} & \textbf{dupFlag} \\
   0 & weather & 5 & False & 83 & True \\
   1 & computer & 2 & True & 82 & False \\
 \end{tabular}
 \caption{MQTT Messages}
 \label{tab:messages}
\end{table}

To realize the benchmark with Apache Storm I tried two different topologies.
The first with only one Bolt, which is the non parallelism way.
\begin{figure}[H]
\centering
\captionsetup{justification=centering}
\includegraphics[width=0.4\textwidth]{images/benchmark_topic1.png}
\caption[Benchmark 1 Bolt]{Benchmark 1 Bolt}
\end{figure}

For the second approach I used four Bolts for parallelism.
The decision for four Bolts depends on the four cores of the notebook which I used for the benchmarks.


\begin{figure}[H]
\centering
\captionsetup{justification=centering}
\includegraphics[width=0.4\textwidth]{images/benchmark_topic2.png}
\caption[Benchmark 4 Bolts]{Benchmark 4 Bolts}
\end{figure}

\newpage

\begin{figure}[H]
\centering
\captionsetup{justification=centering}
\includegraphics[width=1.0\textwidth]{images/benchmark.png}
\caption[Benchmark Diagramm]{Benchmark Diagramm}
\end{figure}

The blue curve was the non parallel one with only one Bolt and
the red was the parallel way with four Bolts.

\subsection{Conclusion}
To take a good conclusion out of this benchmark is a hard tasks.
On the one hand side it's no problem for storm to process millions of messages.
But on the other hand side I couldn't perform better with more messages. It was more or less a linear behavior.
And a bit unsuspected was that the parallelism topic was slower than to work with only one Bolt.
Maybe this behavior would change with bigger messages.
I think the bottleneck in the construction was the communication with Kafka. And so the throughput was limited by the networking.





